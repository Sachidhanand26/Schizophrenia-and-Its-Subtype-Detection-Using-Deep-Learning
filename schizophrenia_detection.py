# -*- coding: utf-8 -*-
"""Schizophrenia Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16FAVcjUbSjbX6ryEqqKYdepWsU2BMRFL
"""

from google.colab import drive
drive.mount('/content/drive')

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
import pandas as pd
import numpy as np

# Function to classify subtype based on keywords
def classify_subtype(text):
    # Subtype keywords dictionary
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Initialize the classifier with tuned parameters
classifier_schizo = LogisticRegression(max_iter=2000, solver='saga', C=0.5)

# Define number of epochs
epochs = 50

# Training and evaluation over 50 epochs for schizophrenia classification
for epoch in range(epochs):
    classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

    # Training predictions and metrics
    y_train_pred_schizo = classifier_schizo.predict(X_train_tfidf_schizo)
    train_accuracy_schizo = accuracy_score(y_train_schizo, y_train_pred_schizo)
    train_loss_schizo = log_loss(y_train_schizo, classifier_schizo.predict_proba(X_train_tfidf_schizo))

    # Evaluate on test data
    y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
    test_accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
    test_loss_schizo = log_loss(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo))
    precision_schizo = precision_score(y_test_schizo, y_pred_schizo)
    recall_schizo = recall_score(y_test_schizo, y_pred_schizo)
    f1_schizo = f1_score(y_test_schizo, y_pred_schizo)
    auc_schizo = roc_auc_score(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo)[:, 1])

    # Cross-validation for schizophrenia classification
    cv_scores = cross_val_score(classifier_schizo, X_train_tfidf_schizo, y_train_schizo, cv=5)
    avg_cv_accuracy = np.mean(cv_scores)

    # Print metrics
    print(f"Epoch {epoch + 1} Schizophrenia Classification Metrics:")
    print("Training Accuracy:", train_accuracy_schizo)
    print("Training Loss:", train_loss_schizo)
    print("Testing Accuracy:", test_accuracy_schizo)
    print("Testing Loss:", test_loss_schizo)
    print("Precision:", precision_schizo)
    print("Recall:", recall_schizo)
    print("F1 Score:", f1_schizo)
    print("AUC:", auc_schizo)
    print("Cross-Validation Accuracy Scores:", cv_scores)
    print("Average CV Accuracy:", avg_cv_accuracy)
    print("\n")

# Subtype classification (similar process)
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Initialize classifier for subtype classification with adjusted settings
classifier_subtype = LogisticRegression(max_iter=2000, solver='saga', C=0.5)

# Training and evaluation for 50 epochs for subtype classification
for epoch in range(epochs):
    classifier_subtype.fit(X_train_tfidf_subtype, y_train_subtype)

    # Training predictions and metrics
    y_train_pred_subtype = classifier_subtype.predict(X_train_tfidf_subtype)
    train_accuracy_subtype = accuracy_score(y_train_subtype, y_train_pred_subtype)
    train_loss_subtype = log_loss(y_train_subtype, classifier_subtype.predict_proba(X_train_tfidf_subtype))

    # Evaluate on test data
    y_pred_subtype = classifier_subtype.predict(X_test_tfidf_subtype)
    test_accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
    test_loss_subtype = log_loss(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype))
    precision_subtype = precision_score(y_test_subtype, y_pred_subtype, average='weighted')
    recall_subtype = recall_score(y_test_subtype, y_pred_subtype, average='weighted')
    f1_subtype = f1_score(y_test_subtype, y_pred_subtype, average='weighted')
    auc_subtype = roc_auc_score(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype), multi_class='ovr')

    # Print metrics
    print(f"Epoch {epoch + 1} Subtype Classification Metrics:")
    print("Training Accuracy:", train_accuracy_subtype)
    print("Training Loss:", train_loss_subtype)
    print("Testing Accuracy:", test_accuracy_subtype)
    print("Testing Loss:", test_loss_subtype)
    print("Precision:", precision_subtype)
    print("Recall:", recall_subtype)
    print("F1 Score:", f1_subtype)
    print("AUC:", auc_subtype)
    print("\n")

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
import pandas as pd
import numpy as np

# Function to classify subtype based on keywords
def classify_subtype(text):
    # Subtype keywords dictionary
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']
y_schizophrenic = df['is_schizophrenic']
y_subtype = df['subtype']

# Split dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Initialize the classifier with tuned parameters
classifier_schizo = LogisticRegression(max_iter=2000, solver='saga', C=0.5)

# Define early stopping criteria
epochs = 50
best_auc = 0
patience = 5  # Stop if performance does not improve for 5 epochs
wait = 0

# Training loop for schizophrenia classification
for epoch in range(epochs):
    classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

    # Predictions and metrics on training data
    y_train_pred_schizo = classifier_schizo.predict(X_train_tfidf_schizo)
    train_accuracy_schizo = accuracy_score(y_train_schizo, y_train_pred_schizo)
    train_loss_schizo = log_loss(y_train_schizo, classifier_schizo.predict_proba(X_train_tfidf_schizo))

    # Predictions and metrics on test data
    y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
    test_accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
    test_loss_schizo = log_loss(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo))
    precision_schizo = precision_score(y_test_schizo, y_pred_schizo)
    recall_schizo = recall_score(y_test_schizo, y_pred_schizo)
    f1_schizo = f1_score(y_test_schizo, y_pred_schizo)
    auc_schizo = roc_auc_score(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo)[:, 1])

    # Cross-validation
    cv_scores = cross_val_score(classifier_schizo, X_train_tfidf_schizo, y_train_schizo, cv=5)
    avg_cv_accuracy = np.mean(cv_scores)

    # Early stopping logic based on AUC
    if auc_schizo > best_auc:
        best_auc = auc_schizo
        wait = 0  # Reset patience counter
    else:
        wait += 1
        if wait >= patience:
            print(f"Early stopping at epoch {epoch + 1}")
            break

    # Print metrics
    print(f"Epoch {epoch + 1} Schizophrenia Classification Metrics:")
    print("Training Accuracy:", train_accuracy_schizo)
    print("Training Loss:", train_loss_schizo)
    print("Testing Accuracy:", test_accuracy_schizo)
    print("Testing Loss:", test_loss_schizo)
    print("Precision:", precision_schizo)
    print("Recall:", recall_schizo)
    print("F1 Score:", f1_schizo)
    print("AUC:", auc_schizo)
    print("Cross-Validation Accuracy Scores:", cv_scores)
    print("Average CV Accuracy:", avg_cv_accuracy)
    print("\n")

# Subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Initialize classifier for subtype classification
classifier_subtype = LogisticRegression(max_iter=2000, solver='saga', C=0.5)

# Training loop for subtype classification
for epoch in range(epochs):
    classifier_subtype.fit(X_train_tfidf_subtype, y_train_subtype)

    # Training metrics
    y_train_pred_subtype = classifier_subtype.predict(X_train_tfidf_subtype)
    train_accuracy_subtype = accuracy_score(y_train_subtype, y_train_pred_subtype)
    train_loss_subtype = log_loss(y_train_subtype, classifier_subtype.predict_proba(X_train_tfidf_subtype))

    # Test metrics
    y_pred_subtype = classifier_subtype.predict(X_test_tfidf_subtype)
    test_accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
    test_loss_subtype = log_loss(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype))
    precision_subtype = precision_score(y_test_subtype, y_pred_subtype, average='weighted')
    recall_subtype = recall_score(y_test_subtype, y_pred_subtype, average='weighted')
    f1_subtype = f1_score(y_test_subtype, y_pred_subtype, average='weighted')
    auc_subtype = roc_auc_score(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype), multi_class='ovr')

    # Print subtype metrics
    print(f"Epoch {epoch + 1} Subtype Classification Metrics:")
    print("Training Accuracy:", train_accuracy_subtype)
    print("Training Loss:", train_loss_subtype)
    print("Testing Accuracy:", test_accuracy_subtype)
    print("Testing Loss:", test_loss_subtype)
    print("Precision:", precision_subtype)
    print("Recall:", recall_subtype)
    print("F1 Score:", f1_subtype)
    print("AUC:", auc_subtype)
    print("\n")

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
from sklearn.feature_selection import SelectKBest, chi2
import pandas as pd
import numpy as np

# Function to classify subtype based on keywords
def classify_subtype(text):
    # Subtype keywords dictionary
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Feature Selection
selector = SelectKBest(chi2, k=3000)  # Select top 3000 features
X_train_selected_schizo = selector.fit_transform(X_train_tfidf_schizo, y_train_schizo)
X_test_selected_schizo = selector.transform(X_test_tfidf_schizo)

# Hyperparameter tuning
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength
    'solver': ['liblinear', 'saga']  # Solvers for logistic regression
}

grid_search = GridSearchCV(LogisticRegression(max_iter=2000), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_selected_schizo, y_train_schizo)

best_model = grid_search.best_estimator_

# Evaluate on test data
y_pred_schizo = best_model.predict(X_test_selected_schizo)
test_accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
precision_schizo = precision_score(y_test_schizo, y_pred_schizo)
recall_schizo = recall_score(y_test_schizo, y_pred_schizo)
f1_schizo = f1_score(y_test_schizo, y_pred_schizo)
auc_schizo = roc_auc_score(y_test_schizo, best_model.predict_proba(X_test_selected_schizo)[:, 1])
test_loss_schizo = log_loss(y_test_schizo, best_model.predict_proba(X_test_selected_schizo))

# Print metrics
print("Best Hyperparameters:", grid_search.best_params_)
print("Testing Accuracy:", test_accuracy_schizo)
print("Precision:", precision_schizo)
print("Recall:", recall_schizo)
print("F1 Score:", f1_schizo)
print("AUC:", auc_schizo)
print("Testing Loss:", test_loss_schizo)

# Subtype classification (similar process)
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Feature Selection for subtype classification
X_train_selected_subtype = selector.fit_transform(X_train_tfidf_subtype, y_train_subtype)
X_test_selected_subtype = selector.transform(X_test_tfidf_subtype)

# Hyperparameter tuning for subtype classification
grid_search_subtype = GridSearchCV(LogisticRegression(max_iter=2000), param_grid, cv=5, scoring='accuracy')
grid_search_subtype.fit(X_train_selected_subtype, y_train_subtype)

best_model_subtype = grid_search_subtype.best_estimator_

# Evaluate on test data
y_pred_subtype = best_model_subtype.predict(X_test_selected_subtype)
test_accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
precision_subtype = precision_score(y_test_subtype, y_pred_subtype, average='weighted')
recall_subtype = recall_score(y_test_subtype, y_pred_subtype, average='weighted')
f1_subtype = f1_score(y_test_subtype, y_pred_subtype, average='weighted')
auc_subtype = roc_auc_score(y_test_subtype, best_model_subtype.predict_proba(X_test_selected_subtype), multi_class='ovr')
test_loss_subtype = log_loss(y_test_subtype, best_model_subtype.predict_proba(X_test_selected_subtype))

# Print metrics
print("Best Hyperparameters for Subtype:", grid_search_subtype.best_params_)
print("Testing Accuracy for Subtype:", test_accuracy_subtype)
print("Precision for Subtype:", precision_subtype)
print("Recall for Subtype:", recall_subtype)
print("F1 Score for Subtype:", f1_subtype)
print("AUC for Subtype:", auc_subtype)
print("Testing Loss for Subtype:", test_loss_subtype)

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
from sklearn.feature_selection import SelectKBest, chi2
import pandas as pd

# Function to classify subtype based on keywords
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type
    return 'undifferentiated'

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Feature Selection
selector = SelectKBest(chi2, k=3000)  # Select top 3000 features
X_train_selected_schizo = selector.fit_transform(X_train_tfidf_schizo, y_train_schizo)
X_test_selected_schizo = selector.transform(X_test_tfidf_schizo)

# Hyperparameter tuning with epochs
epochs = 50  # Set the number of epochs to 50
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength
    'solver': ['liblinear', 'saga']  # Solvers for logistic regression
}

# Store the best results for schizophrenia classification
best_results_schizo = {}

# Custom loop for schizophrenia classification
for epoch in range(1, epochs + 1):  # Loop through 1 to 50
    best_accuracy = 0
    best_metrics = {}

    for C in param_grid['C']:
        for solver in param_grid['solver']:
            model = LogisticRegression(C=C, solver=solver, max_iter=2000)
            model.fit(X_train_selected_schizo, y_train_schizo)

            # Evaluate on test data
            y_pred_test = model.predict(X_test_selected_schizo)
            test_accuracy_schizo = accuracy_score(y_test_schizo, y_pred_test)

            # Keep track of the best metrics for this epoch
            if test_accuracy_schizo > best_accuracy:
                best_accuracy = test_accuracy_schizo
                best_metrics = {
                    'C': C,
                    'Solver': solver,
                    'Accuracy': test_accuracy_schizo,
                    'Precision': precision_score(y_test_schizo, y_pred_test),
                    'Recall': recall_score(y_test_schizo, y_pred_test),
                    'F1 Score': f1_score(y_test_schizo, y_pred_test),
                    'AUC': roc_auc_score(y_test_schizo, model.predict_proba(X_test_selected_schizo)[:, 1]),
                    'Loss': log_loss(y_test_schizo, model.predict_proba(X_test_selected_schizo))
                }

    # Store the best results for the epoch
    best_results_schizo[epoch] = best_metrics

# Print the best results for each epoch for schizophrenia classification
for epoch, metrics in best_results_schizo.items():
    print(f"Epoch: {epoch}, Best Hyperparameters C={metrics['C']}, Solver={metrics['Solver']}")
    print("Testing Accuracy:", metrics['Accuracy'])
    print("Precision:", metrics['Precision'])
    print("Recall:", metrics['Recall'])
    print("F1 Score:", metrics['F1 Score'])
    print("AUC:", metrics['AUC'])
    print("Testing Loss:", metrics['Loss'])
    print("=" * 50)

# Subtype classification (similar process)
# Split the dataset for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Feature Selection for subtype classification
X_train_selected_subtype = selector.fit_transform(X_train_tfidf_subtype, y_train_subtype)
X_test_selected_subtype = selector.transform(X_test_tfidf_subtype)

# Store the best results for subtype classification
best_results_subtype = {}

# Custom loop for subtype classification
for epoch in range(1, epochs + 1):  # Loop through 1 to 50
    best_accuracy = 0
    best_metrics = {}

    for C in param_grid['C']:
        for solver in param_grid['solver']:
            model = LogisticRegression(C=C, solver=solver, max_iter=2000)
            model.fit(X_train_selected_subtype, y_train_subtype)

            # Evaluate on test data
            y_pred_test = model.predict(X_test_selected_subtype)
            test_accuracy_subtype = accuracy_score(y_test_subtype, y_pred_test)

            # Keep track of the best metrics for this epoch
            if test_accuracy_subtype > best_accuracy:
                best_accuracy = test_accuracy_subtype
                best_metrics = {
                    'C': C,
                    'Solver': solver,
                    'Accuracy': test_accuracy_subtype,
                    'Precision': precision_score(y_test_subtype, y_pred_test, average='weighted'),
                    'Recall': recall_score(y_test_subtype, y_pred_test, average='weighted'),
                    'F1 Score': f1_score(y_test_subtype, y_pred_test, average='weighted'),
                    'AUC': roc_auc_score(y_test_subtype, model.predict_proba(X_test_selected_subtype), multi_class='ovr'),
                    'Loss': log_loss(y_test_subtype, model.predict_proba(X_test_selected_subtype))
                }

    # Store the best results for the epoch
    best_results_subtype[epoch] = best_metrics

# Print the best results for each epoch for subtype classification
for epoch, metrics in best_results_subtype.items():
    print(f"Epoch: {epoch}, Best Hyperparameters C={metrics['C']}, Solver={metrics['Solver']}")
    print("Testing Accuracy:", metrics['Accuracy'])
    print("Precision:", metrics['Precision'])
    print("Recall:", metrics['Recall'])
    print("F1 Score:", metrics['F1 Score'])
    print("AUC:", metrics['AUC'])
    print("Testing Loss:", metrics['Loss'])
    print("=" * 50)

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
from sklearn.feature_selection import SelectKBest, chi2
import pandas as pd

# Function to classify subtype based on keywords
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety', 'plot'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type
    return 'undifferentiated'

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Feature Selection
selector = SelectKBest(chi2, k=3000)  # Select top 3000 features
X_train_selected_schizo = selector.fit_transform(X_train_tfidf_schizo, y_train_schizo)
X_test_selected_schizo = selector.transform(X_test_tfidf_schizo)

# Hyperparameter tuning with epochs
epochs = 50  # Set the number of epochs to 50
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength
    'solver': ['liblinear', 'saga']  # Solvers for logistic regression
}

# Store the best results for schizophrenia classification
best_results_schizo = {}

# Custom loop for schizophrenia classification with training accuracy and loss
for epoch in range(1, epochs + 1):  # Loop through 1 to 50
    best_accuracy = 0
    best_metrics = {}

    for C in param_grid['C']:
        for solver in param_grid['solver']:
            model = LogisticRegression(C=C, solver=solver, max_iter=2000)
            model.fit(X_train_selected_schizo, y_train_schizo)

            # Evaluate on test data
            y_pred_test = model.predict(X_test_selected_schizo)
            y_pred_train = model.predict(X_train_selected_schizo)

            test_accuracy_schizo = accuracy_score(y_test_schizo, y_pred_test)
            train_accuracy_schizo = accuracy_score(y_train_schizo, y_pred_train)

            # Compute probabilities for loss calculation
            y_pred_prob_test = model.predict_proba(X_test_selected_schizo)
            y_pred_prob_train = model.predict_proba(X_train_selected_schizo)

            test_loss_schizo = log_loss(y_test_schizo, y_pred_prob_test)
            train_loss_schizo = log_loss(y_train_schizo, y_pred_prob_train)

            # Keep track of the best metrics for this epoch
            if test_accuracy_schizo > best_accuracy:
                best_accuracy = test_accuracy_schizo
                best_metrics = {
                    'C': C,
                    'Solver': solver,
                    'Train Accuracy': train_accuracy_schizo,
                    'Test Accuracy': test_accuracy_schizo,
                    'Train Loss': train_loss_schizo,
                    'Test Loss': test_loss_schizo,
                    'Precision': precision_score(y_test_schizo, y_pred_test),
                    'Recall': recall_score(y_test_schizo, y_pred_test),
                    'F1 Score': f1_score(y_test_schizo, y_pred_test),
                    'AUC': roc_auc_score(y_test_schizo, y_pred_prob_test[:, 1])
                }

    # Store the best results for the epoch
    best_results_schizo[epoch] = best_metrics

# Print the best results for each epoch for schizophrenia classification
for epoch, metrics in best_results_schizo.items():
    print(f"Epoch: {epoch}, Best Hyperparameters C={metrics['C']}, Solver={metrics['Solver']}")
    print("Train Accuracy:", metrics['Train Accuracy'])
    print("Test Accuracy:", metrics['Test Accuracy'])
    print("Train Loss:", metrics['Train Loss'])
    print("Test Loss:", metrics['Test Loss'])
    print("Precision:", metrics['Precision'])
    print("Recall:", metrics['Recall'])
    print("F1 Score:", metrics['F1 Score'])
    print("AUC:", metrics['AUC'])
    print("=" * 50)

# Subtype classification (similar process)
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Feature Selection for subtype classification
X_train_selected_subtype = selector.fit_transform(X_train_tfidf_subtype, y_train_subtype)
X_test_selected_subtype = selector.transform(X_test_tfidf_subtype)

# Store the best results for subtype classification
best_results_subtype = {}

# Custom loop for subtype classification with training accuracy and loss
for epoch in range(1, epochs + 1):  # Loop through 1 to 50
    best_accuracy = 0
    best_metrics = {}

    for C in param_grid['C']:
        for solver in param_grid['solver']:
            model = LogisticRegression(C=C, solver=solver, max_iter=2000)
            model.fit(X_train_selected_subtype, y_train_subtype)

            # Evaluate on test and train data
            y_pred_test = model.predict(X_test_selected_subtype)
            y_pred_train = model.predict(X_train_selected_subtype)

            test_accuracy_subtype = accuracy_score(y_test_subtype, y_pred_test)
            train_accuracy_subtype = accuracy_score(y_train_subtype, y_pred_train)

            # Compute probabilities for loss calculation
            y_pred_prob_test = model.predict_proba(X_test_selected_subtype)
            y_pred_prob_train = model.predict_proba(X_train_selected_subtype)

            test_loss_subtype = log_loss(y_test_subtype, y_pred_prob_test)
            train_loss_subtype = log_loss(y_train_subtype, y_pred_prob_train)

            # Keep track of the best metrics for this epoch
            if test_accuracy_subtype > best_accuracy:
                best_accuracy = test_accuracy_subtype
                best_metrics = {
                    'C': C,
                    'Solver': solver,
                    'Train Accuracy': train_accuracy_subtype,
                    'Test Accuracy': test_accuracy_subtype,
                    'Train Loss': train_loss_subtype,
                    'Test Loss': test_loss_subtype,
                    'Precision': precision_score(y_test_subtype, y_pred_test, average='weighted'),
                    'Recall': recall_score(y_test_subtype, y_pred_test, average='weighted'),
                    'F1 Score': f1_score(y_test_subtype, y_pred_test, average='weighted'),
                    'AUC': roc_auc_score(y_test_subtype, y_pred_prob_test, multi_class='ovr')
                }

    # Store the best results for the epoch
    best_results_subtype[epoch] = best_metrics

# Print the best results for each epoch for subtype classification
for epoch, metrics in best_results_subtype.items():
    print(f"Epoch: {epoch}, Best Hyperparameters C={metrics['C']}, Solver={metrics['Solver']}")
    print("Train Accuracy:", metrics['Train Accuracy'])
    print("Test Accuracy:", metrics['Test Accuracy'])
    print("Train Loss:", metrics['Train Loss'])
    print("Test Loss:", metrics['Test Loss'])
    print("Precision:", metrics['Precision'])
    print("Recall:", metrics['Recall'])
    print("F1 Score:", metrics['F1 Score'])
    print("AUC:", metrics['AUC'])
    print("=" * 50)

#Logistic Regression

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
import pandas as pd

# Function to classify subtype based on keywords
def classify_subtype(text):
    # Subtype keywords dictionary
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text in the dataset
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Initialize classifier for schizophrenia classification
classifier_schizo = LogisticRegression(max_iter=1000)

# Define number of epochs
epochs = 50

# Training and evaluation for schizophrenia classification
for epoch in range(epochs):
    # Train classifier
    classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

    # Training predictions and metrics
    y_train_pred_schizo = classifier_schizo.predict(X_train_tfidf_schizo)
    train_accuracy_schizo = accuracy_score(y_train_schizo, y_train_pred_schizo)
    train_loss_schizo = log_loss(y_train_schizo, classifier_schizo.predict_proba(X_train_tfidf_schizo))

    # Evaluate classifier on test data
    y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
    test_accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
    test_loss_schizo = log_loss(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo))
    precision_schizo = precision_score(y_test_schizo, y_pred_schizo)
    recall_schizo = recall_score(y_test_schizo, y_pred_schizo)
    f1_schizo = f1_score(y_test_schizo, y_pred_schizo)
    auc_schizo = roc_auc_score(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo)[:, 1])

    # Print metrics
    print(f"Schizophrenia Classification Metrics (Epoch {epoch+1}):")
    print("Training Accuracy:", train_accuracy_schizo)
    print("Training Loss:", train_loss_schizo)
    print("Testing Accuracy:", test_accuracy_schizo)
    print("Testing Loss:", test_loss_schizo)
    print("Precision:", precision_schizo)
    print("Recall:", recall_schizo)
    print("F1 Score:", f1_schizo)
    print("AUC:", auc_schizo)

# Split the dataset for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Initialize classifier for subtype classification
classifier_subtype = LogisticRegression(max_iter=1000)

# Training and evaluation for subtype classification
for epoch in range(epochs):
    # Train classifier
    classifier_subtype.fit(X_train_tfidf_subtype, y_train_subtype)

    # Training predictions and metrics
    y_train_pred_subtype = classifier_subtype.predict(X_train_tfidf_subtype)
    train_accuracy_subtype = accuracy_score(y_train_subtype, y_train_pred_subtype)
    train_loss_subtype = log_loss(y_train_subtype, classifier_subtype.predict_proba(X_train_tfidf_subtype))

    # Evaluate classifier on test data
    y_pred_subtype = classifier_subtype.predict(X_test_tfidf_subtype)
    test_accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
    test_loss_subtype = log_loss(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype))
    precision_subtype = precision_score(y_test_subtype, y_pred_subtype, average='weighted')
    recall_subtype = recall_score(y_test_subtype, y_pred_subtype, average='weighted')
    f1_subtype = f1_score(y_test_subtype, y_pred_subtype, average='weighted')
    auc_subtype = roc_auc_score(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype), multi_class='ovr')

    # Print metrics
    print(f"\nSubtype Classification Metrics (Epoch {epoch+1}):")
    print("Training Accuracy:", train_accuracy_subtype)
    print("Training Loss:", train_loss_subtype)
    print("Testing Accuracy:", test_accuracy_subtype)
    print("Testing Loss:", test_loss_subtype)
    print("Precision:", precision_subtype)
    print("Recall:", recall_subtype)
    print("F1 Score:", f1_subtype)
    print("AUC:", auc_subtype)

#Random Forest

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
import pandas as pd

# Function to classify subtype based on keywords
def classify_subtype(text):
    # Subtype keywords dictionary
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text in the dataset
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Initialize classifier for schizophrenia classification
classifier_schizo = RandomForestClassifier(n_estimators=100)  # or any other appropriate parameters for RandomForest

# Define number of epochs
epochs = 50

# Training and evaluation for schizophrenia classification
for epoch in range(epochs):
    # Train classifier
    classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

    # Training predictions and metrics
    y_train_pred_schizo = classifier_schizo.predict(X_train_tfidf_schizo)
    train_accuracy_schizo = accuracy_score(y_train_schizo, y_train_pred_schizo)
    train_loss_schizo = log_loss(y_train_schizo, classifier_schizo.predict_proba(X_train_tfidf_schizo))

    # Evaluate classifier on test data
    y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
    test_accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
    test_loss_schizo = log_loss(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo))
    precision_schizo = precision_score(y_test_schizo, y_pred_schizo)
    recall_schizo = recall_score(y_test_schizo, y_pred_schizo)
    f1_schizo = f1_score(y_test_schizo, y_pred_schizo)
    auc_schizo = roc_auc_score(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo)[:, 1])

    # Print metrics
    print(f"Schizophrenia Classification Metrics (Epoch {epoch+1}):")
    print("Training Accuracy:", train_accuracy_schizo)
    print("Training Loss:", train_loss_schizo)
    print("Testing Accuracy:", test_accuracy_schizo)
    print("Testing Loss:", test_loss_schizo)
    print("Precision:", precision_schizo)
    print("Recall:", recall_schizo)
    print("F1 Score:", f1_schizo)
    print("AUC:", auc_schizo)

# Split the dataset for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Initialize classifier for subtype classification
classifier_subtype = RandomForestClassifier(n_estimators=100)

# Training and evaluation for subtype classification
for epoch in range(epochs):
    # Train classifier
    classifier_subtype.fit(X_train_tfidf_subtype, y_train_subtype)

    # Training predictions and metrics
    y_train_pred_subtype = classifier_subtype.predict(X_train_tfidf_subtype)
    train_accuracy_subtype = accuracy_score(y_train_subtype, y_train_pred_subtype)
    train_loss_subtype = log_loss(y_train_subtype, classifier_subtype.predict_proba(X_train_tfidf_subtype))

    # Evaluate classifier on test data
    y_pred_subtype = classifier_subtype.predict(X_test_tfidf_subtype)
    test_accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
    test_loss_subtype = log_loss(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype))
    precision_subtype = precision_score(y_test_subtype, y_pred_subtype, average='weighted')
    recall_subtype = recall_score(y_test_subtype, y_pred_subtype, average='weighted')
    f1_subtype = f1_score(y_test_subtype, y_pred_subtype, average='weighted')
    auc_subtype = roc_auc_score(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype), multi_class='ovr')

    # Print metrics
    print(f"\nSubtype Classification Metrics (Epoch {epoch+1}):")
    print("Training Accuracy:", train_accuracy_subtype)
    print("Training Loss:", train_loss_subtype)
    print("Testing Accuracy:", test_accuracy_subtype)
    print("Testing Loss:", test_loss_subtype)
    print("Precision:", precision_subtype)
    print("Recall:", recall_subtype)
    print("F1 Score:", f1_subtype)
    print("AUC:", auc_subtype)

#LSTM

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text in the dataset
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type
    return 'undifferentiated'

df['subtype'] = df['clean_text'].apply(classify_subtype)

# Text preprocessing and tokenization
max_words = 5000
max_sequence_length = 100
embedding_dim = 100

# Tokenizer for schizophrenia classification
tokenizer_schizo = Tokenizer(num_words=max_words)
tokenizer_schizo.fit_on_texts(df['clean_text'])
X_sequences_schizo = tokenizer_schizo.texts_to_sequences(df['clean_text'])
X_padded_schizo = pad_sequences(X_sequences_schizo, maxlen=max_sequence_length)

# Encode the target variable for schizophrenia classification
y_schizophrenic = df['is_schizophrenic'].values

# Split the dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X_padded_schizo, y_schizophrenic, test_size=0.2, random_state=42)

# Build LSTM model for schizophrenia classification
model_schizo = Sequential()
model_schizo.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))
model_schizo.add(LSTM(64, return_sequences=True))
model_schizo.add(Dropout(0.5))
model_schizo.add(LSTM(64))
model_schizo.add(Dense(1, activation='sigmoid'))

model_schizo.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model_schizo.fit(X_train_schizo, y_train_schizo, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the model
y_pred_schizo = model_schizo.predict(X_test_schizo).ravel()
y_pred_schizo_binary = (y_pred_schizo > 0.5).astype(int)
print("Schizophrenia Classification Metrics:")
print("Accuracy:", accuracy_score(y_test_schizo, y_pred_schizo_binary))
print("Precision:", precision_score(y_test_schizo, y_pred_schizo_binary))
print("Recall:", recall_score(y_test_schizo, y_pred_schizo_binary))
print("F1 Score:", f1_score(y_test_schizo, y_pred_schizo_binary))
print("AUC:", roc_auc_score(y_test_schizo, y_pred_schizo))
print("Log Loss:", log_loss(y_test_schizo, y_pred_schizo))

# Tokenizer for subtype classification
tokenizer_subtype = Tokenizer(num_words=max_words)
tokenizer_subtype.fit_on_texts(df['clean_text'])
X_sequences_subtype = tokenizer_subtype.texts_to_sequences(df['clean_text'])
X_padded_subtype = pad_sequences(X_sequences_subtype, maxlen=max_sequence_length)

# Encode the target variable for subtype classification
y_subtype = df['subtype'].values
label_encoder_subtype = LabelEncoder()
y_subtype_encoded = label_encoder_subtype.fit_transform(y_subtype)
y_subtype_encoded = to_categorical(y_subtype_encoded)  # One-hot encoding

# Split the dataset for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X_padded_subtype, y_subtype_encoded, test_size=0.2, random_state=42)

# Build LSTM model for subtype classification
model_subtype = Sequential()
model_subtype.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))
model_subtype.add(LSTM(64, return_sequences=True))
model_subtype.add(Dropout(0.5))
model_subtype.add(LSTM(64))
model_subtype.add(Dense(len(label_encoder_subtype.classes_), activation='softmax'))

model_subtype.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model_subtype.fit(X_train_subtype, y_train_subtype, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the model
y_pred_subtype = model_subtype.predict(X_test_subtype)
y_pred_subtype_classes = np.argmax(y_pred_subtype, axis=1)
y_test_subtype_classes = np.argmax(y_test_subtype, axis=1)

print("\nSubtype Classification Metrics:")
print("Accuracy:", accuracy_score(y_test_subtype_classes, y_pred_subtype_classes))
print("Precision:", precision_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("Recall:", recall_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("F1 Score:", f1_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))

#CNN Model

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Embedding, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss

# CNN Model for Schizophrenia Classification
model_schizo_cnn = Sequential()
model_schizo_cnn.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))
model_schizo_cnn.add(Conv1D(128, 5, activation='relu'))
model_schizo_cnn.add(GlobalMaxPooling1D())
model_schizo_cnn.add(Dropout(0.5))
model_schizo_cnn.add(Dense(64, activation='relu'))
model_schizo_cnn.add(Dense(1, activation='sigmoid'))

model_schizo_cnn.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

# Train the CNN model
model_schizo_cnn.fit(X_train_schizo, y_train_schizo, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the CNN model
y_pred_schizo_cnn = model_schizo_cnn.predict(X_test_schizo).ravel()
y_pred_schizo_cnn_binary = (y_pred_schizo_cnn > 0.5).astype(int)

print("Schizophrenia CNN Classification Metrics:")
print("Accuracy:", accuracy_score(y_test_schizo, y_pred_schizo_cnn_binary))
print("Precision:", precision_score(y_test_schizo, y_pred_schizo_cnn_binary))
print("Recall:", recall_score(y_test_schizo, y_pred_schizo_cnn_binary))
print("F1 Score:", f1_score(y_test_schizo, y_pred_schizo_cnn_binary))
print("AUC:", roc_auc_score(y_test_schizo, y_pred_schizo_cnn))
print("Log Loss:", log_loss(y_test_schizo, y_pred_schizo_cnn))

# CNN Model for Subtype Classification
model_subtype_cnn = Sequential()
model_subtype_cnn.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))
model_subtype_cnn.add(Conv1D(128, 5, activation='relu'))
model_subtype_cnn.add(GlobalMaxPooling1D())
model_subtype_cnn.add(Dropout(0.5))
model_subtype_cnn.add(Dense(64, activation='relu'))
model_subtype_cnn.add(Dense(len(label_encoder_subtype.classes_), activation='softmax'))

model_subtype_cnn.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the CNN model
model_subtype_cnn.fit(X_train_subtype, y_train_subtype, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the CNN model
y_pred_subtype_cnn = model_subtype_cnn.predict(X_test_subtype)
y_pred_subtype_cnn_classes = np.argmax(y_pred_subtype_cnn, axis=1)
y_test_subtype_cnn_classes = np.argmax(y_test_subtype, axis=1)

print("\nSubtype CNN Classification Metrics:")
print("Accuracy:", accuracy_score(y_test_subtype_cnn_classes, y_pred_subtype_cnn_classes))
print("Precision:", precision_score(y_test_subtype_cnn_classes, y_pred_subtype_cnn_classes, average='weighted'))
print("Recall:", recall_score(y_test_subtype_cnn_classes, y_pred_subtype_cnn_classes, average='weighted'))
print("F1 Score:", f1_score(y_test_subtype_cnn_classes, y_pred_subtype_cnn_classes, average='weighted'))

"""Seperate Use Case"""

#Random Forest

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

# Function to classify subtype based on keywords
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
        # Add more subtypes and their associated keywords as needed
    }

    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'  # If no subtype keywords are found

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')  # Replace 'dataset.csv' with the path to your dataset

# Apply subtype classification to each text in the dataset
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset into training and testing sets for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for schizophrenia classification
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Train a classifier for schizophrenia classification
classifier_schizo = RandomForestClassifier(n_estimators=100, random_state=42)  # Random Forest classifier
classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

# Evaluate the classifier for schizophrenia classification
y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
print("Accuracy for schizophrenia classification:", accuracy_schizo)

# Classify user input for schizophrenia classification
user_input_schizo = input("Enter the text to classify for schizophrenia: ")
user_input_tfidf_schizo = tfidf_vectorizer_schizo.transform([user_input_schizo])
prediction_schizo = classifier_schizo.predict(user_input_tfidf_schizo)
if prediction_schizo[0] == 1:
    print("The text is classified as schizophrenic.")
else:
    print("The text is classified as non-schizophrenic.")

# Split the dataset into training and testing sets for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Train a classifier for subtype classification
classifier_subtype = RandomForestClassifier(n_estimators=100, random_state=42)  # Random Forest classifier
classifier_subtype.fit(X_train_tfidf_subtype, y_train_subtype)

# Evaluate the classifier for subtype classification
y_pred_subtype = classifier_subtype.predict(X_test_tfidf_subtype)
accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
print("Accuracy for subtype classification:", accuracy_subtype)

# Classify user input for subtype classification
user_input_subtype = input("Enter the text to classify for subtype: ")
user_input_tfidf_subtype = tfidf_vectorizer_subtype.transform([user_input_subtype])
prediction_subtype = classifier_subtype.predict(user_input_tfidf_subtype)
print("The text is classified as subtype:", prediction_subtype[0])

#Logistic Regression For Schizophrenia Prediction

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import pandas as pd

# Load the dataset
# Replace 'your_dataset.csv' with the path to your dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Preprocessing
X = df['clean_text']  # Features
y = df['is_schizophrenic']  # Target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train a classifier
classifier = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier.fit(X_train_tfidf, y_train)

# Evaluate the classifier
y_pred = classifier.predict(X_test_tfidf)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Classify user input
user_input = input("Enter the text to classify: ")
user_input_tfidf = tfidf_vectorizer.transform([user_input])
prediction = classifier.predict(user_input_tfidf)
if prediction[0] == 1:
    print("The text is classified as schizophrenic.")
else:
    print("The text is classified as non-schizophrenic.")

#Test Case Generator For Subtype

import random

# Keywords for each subtype
sub_type_keywords = {
    'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                 'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                 'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                 'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                 'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                 'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
    'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                     'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                     'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                     'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                     'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                     'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                     'scattered', 'muddle', 'disarranged'],
    'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                  'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                  'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                  'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                  'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                  'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                  'pinned'],
    'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                 'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                 'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                 'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                 'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                 'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                 'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
    'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                         'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                         'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                         'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                         'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                         'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                         'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                         'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
    # Add more subtypes and their associated keywords as needed
}

# Generate test cases
test_cases = []
for i in range(2000):
    text = ""
    num_keywords = random.randint(1, 5)  # Choose a random number of keywords for each test case
    selected_sub_type = random.choice(list(sub_type_keywords.keys()))  # Randomly select a subtype
    keywords = random.sample(sub_type_keywords[selected_sub_type], num_keywords)  # Randomly select keywords for the subtype
    text = " ".join(keywords)
    test_cases.append((text, selected_sub_type))

# Print the generated test cases
for idx, (text, subtype) in enumerate(test_cases, start=1):
    print(f"Test Case {idx}:")
    print(f"Text: {text}")
    print(f"Expected Subtype: {subtype}\n")

#Test Case Generator

import random

def generate_testcases(num_testcases):
    testcases = []
    subtypes = ['paranoid', 'disorganized', 'catatonic', 'residual', 'undifferentiated']

    for _ in range(num_testcases):
        text = "I'm"

        # Randomly add additional phrases to the text
        phrases = [
            " constantly feel like someone is following me, and I hear voices whispering in my ear.",
            " thoughts are so chaotic and disorganized, I can't make sense of anything anymore.",
            " feel completely rigid and motionless, like I'm trapped in my own body.",
            " completely paralyzed by fear, unable to move or react to anything around me.",
            " stuck in a catatonic state, feeling completely disconnected from the world around me.",
            " constantly on edge, feeling like I'm being watched and followed everywhere I go.",
            " completely immobilized, like I'm trapped in my own body and unable to move.",
            " lost in a maze of thoughts, unable to find my way out.",
            " overwhelmed by paranoid thoughts, constantly looking over my shoulder.",
            " trapped in my own body, unable to move or speak.",
            " consumed by fear and suspicion, unable to trust anyone or anything.",
            " frozen in place, unable to break free from this state of paralysis.",
            " tormented by intrusive thoughts, constantly invading my mind.",
            " haunted by paranoid delusions, convinced that someone is out to get me.",
            " plagued by hallucinations, seeing things that aren't there.",
            " trapped in a nightmare, unable to wake up or escape."
        ]

        # Randomly select subtypes and add corresponding phrases to the text
        selected_subtypes = random.sample(subtypes, random.randint(1, len(subtypes)))
        for subtype in selected_subtypes:
            text += " " + phrases[subtypes.index(subtype)]

        testcases.append(text)

    return testcases

# Generate 1000 test cases
testcases = generate_testcases(1000)

# Print the generated test cases
for i, testcase in enumerate(testcases, start=1):
    print(f"{i}. {testcase}")

#Logistic Regression For Schizophrenia and Subtype Prediction

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import pandas as pd

# Function to classify subtype based on keywords
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
        # Add more subtypes and their associated keywords as needed
    }

    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'  # If no subtype keywords are found

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')  # Replace 'dataset.csv' with the path to your dataset

# Apply subtype classification to each text in the dataset
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset into training and testing sets for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for schizophrenia classification
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Train a classifier for schizophrenia classification
classifier_schizo = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

# Evaluate the classifier for schizophrenia classification
y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
print("Accuracy for schizophrenia classification:", accuracy_schizo)

# Classify user input for schizophrenia classification
user_input_schizo = input("Enter the text to classify for schizophrenia: ")
user_input_tfidf_schizo = tfidf_vectorizer_schizo.transform([user_input_schizo])
prediction_schizo = classifier_schizo.predict(user_input_tfidf_schizo)
if prediction_schizo[0] == 1:
    print("The text is classified as schizophrenic.")
else:
    print("The text is classified as non-schizophrenic.")

# Split the dataset into training and testing sets for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Train a classifier for subtype classification
classifier_subtype = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier_subtype.fit(X_train_tfidf_subtype, y_train_subtype)

# Evaluate the classifier for subtype classification
y_pred_subtype = classifier_subtype.predict(X_test_tfidf_subtype)
accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
print("Accuracy for subtype classification:", accuracy_subtype)

# Classify user input for subtype classification
user_input_subtype = input("Enter the text to classify for subtype: ")
user_input_tfidf_subtype = tfidf_vectorizer_subtype.transform([user_input_subtype])
prediction_subtype = classifier_subtype.predict(user_input_tfidf_subtype)
print("The text is classified as subtype:", prediction_subtype[0])

#Logistic Regression With Performance Metrics

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
import pandas as pd

# Function to classify subtype based on keywords
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
        # Add more subtypes and their associated keywords as needed
    }

    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'  # If no subtype keywords are found

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')  # Replace 'dataset.csv' with the path to your dataset

# Apply subtype classification to each text in the dataset
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset into training and testing sets for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for schizophrenia classification
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Train a classifier for schizophrenia classification
classifier_schizo = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

# Evaluate the classifier for schizophrenia classification
y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
training_loss_schizo = log_loss(y_train_schizo, classifier_schizo.predict_proba(X_train_tfidf_schizo))
testing_loss_schizo = log_loss(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo))
precision_schizo = precision_score(y_test_schizo, y_pred_schizo)
recall_schizo = recall_score(y_test_schizo, y_pred_schizo)
f1_schizo = f1_score(y_test_schizo, y_pred_schizo)
auc_schizo = roc_auc_score(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo)[:,1])

print("Schizophrenia Classification Metrics:")
print("Accuracy:", accuracy_schizo)
print("Training Loss:", training_loss_schizo)
print("Testing Loss:", testing_loss_schizo)
print("Precision:", precision_schizo)
print("Recall:", recall_schizo)
print("F1 Score:", f1_schizo)
print("AUC:", auc_schizo)

# Classify user input for schizophrenia classification
user_input_schizo = input("Enter the text to classify for schizophrenia: ")
user_input_tfidf_schizo = tfidf_vectorizer_schizo.transform([user_input_schizo])
prediction_schizo = classifier_schizo.predict(user_input_tfidf_schizo)
if prediction_schizo[0] == 1:
    print("The text is classified as schizophrenic.")
else:
    print("The text is classified as non-schizophrenic.")

# Split the dataset into training and testing sets for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Train a classifier for subtype classification
classifier_subtype = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier_subtype.fit(X_train_tfidf_subtype, y_train_subtype)

# Evaluate the classifier for subtype classification
y_pred_subtype = classifier_subtype.predict(X_test_tfidf_subtype)
accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
training_loss_subtype = log_loss(y_train_subtype, classifier_subtype.predict_proba(X_train_tfidf_subtype))
testing_loss_subtype = log_loss(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype))
precision_subtype = precision_score(y_test_subtype, y_pred_subtype, average='weighted')
recall_subtype = recall_score(y_test_subtype, y_pred_subtype, average='weighted')
f1_subtype = f1_score(y_test_subtype, y_pred_subtype, average='weighted')
auc_subtype = roc_auc_score(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype), multi_class='ovr')

print("\nSubtype Classification Metrics:")
print("Accuracy:", accuracy_subtype)
print("Training Loss:", training_loss_subtype)
print("Testing Loss:", testing_loss_subtype)
print("Precision:", precision_subtype)
print("Recall:", recall_subtype)
print("F1 Score:", f1_subtype)
print("AUC:", auc_subtype)

# Classify user input for subtype classification
user_input_subtype = input("Enter the text to classify for subtype: ")
user_input_tfidf_subtype = tfidf_vectorizer_subtype.transform([user_input_subtype])
prediction_subtype = classifier_subtype.predict(user_input_tfidf_subtype)
print("The text is classified as subtype:", prediction_subtype[0])

#Logistic Regression With Visualization

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
import pandas as pd

# Function to classify subtype based on keywords
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
        # Add more subtypes and their associated keywords as needed
    }

    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'  # If no subtype keywords are found

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')  # Replace 'dataset.csv' with the path to your dataset

# Apply subtype classification to each text in the dataset
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset into training and testing sets for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for schizophrenia classification
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Train a classifier for schizophrenia classification
classifier_schizo = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

# Evaluate the classifier for schizophrenia classification
y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
training_loss_schizo = log_loss(y_train_schizo, classifier_schizo.predict_proba(X_train_tfidf_schizo))
testing_loss_schizo = log_loss(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo))
precision_schizo = precision_score(y_test_schizo, y_pred_schizo)
recall_schizo = recall_score(y_test_schizo, y_pred_schizo)
f1_schizo = f1_score(y_test_schizo, y_pred_schizo)
auc_schizo = roc_auc_score(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo)[:,1])

print("Schizophrenia Classification Metrics:")
print("Accuracy:", accuracy_schizo)
print("Training Loss:", training_loss_schizo)
print("Testing Loss:", testing_loss_schizo)
print("Precision:", precision_schizo)
print("Recall:", recall_schizo)
print("F1 Score:", f1_schizo)
print("AUC:", auc_schizo)

# Classify user input for schizophrenia classification
user_input_schizo = input("Enter the text to classify for schizophrenia: ")
user_input_tfidf_schizo = tfidf_vectorizer_schizo.transform([user_input_schizo])
prediction_schizo = classifier_schizo.predict(user_input_tfidf_schizo)
if prediction_schizo[0] == 1:
    print("The text is classified as schizophrenic.")
else:
    print("The text is classified as non-schizophrenic.")

# Split the dataset into training and testing sets for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Train a classifier for subtype classification
classifier_subtype = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier_subtype.fit(X_train_tfidf_subtype, y_train_subtype)

# Evaluate the classifier for subtype classification
y_pred_subtype = classifier_subtype.predict(X_test_tfidf_subtype)
accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
training_loss_subtype = log_loss(y_train_subtype, classifier_subtype.predict_proba(X_train_tfidf_subtype))
testing_loss_subtype = log_loss(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype))
precision_subtype = precision_score(y_test_subtype, y_pred_subtype, average='weighted')
recall_subtype = recall_score(y_test_subtype, y_pred_subtype, average='weighted')
f1_subtype = f1_score(y_test_subtype, y_pred_subtype, average='weighted')
auc_subtype = roc_auc_score(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype), multi_class='ovr')

print("\nSubtype Classification Metrics:")
print("Accuracy:", accuracy_subtype)
print("Training Loss:", training_loss_subtype)
print("Testing Loss:", testing_loss_subtype)
print("Precision:", precision_subtype)
print("Recall:", recall_subtype)
print("F1 Score:", f1_subtype)
print("AUC:", auc_subtype)

# Classify user input for subtype classification
user_input_subtype = input("Enter the text to classify for subtype: ")
user_input_tfidf_subtype = tfidf_vectorizer_subtype.transform([user_input_subtype])
prediction_subtype = classifier_subtype.predict(user_input_tfidf_subtype)
print("The text is classified as subtype:", prediction_subtype[0])

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
import numpy as np

# Function to classify subtype based on keywords
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
        # Add more subtypes and their associated keywords as needed
    }

    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'undifferentiated'  # If no subtype keywords are found

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')  # Replace 'dataset.csv' with the path to your dataset

# Apply subtype classification to each text in the dataset
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset into training and testing sets for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for schizophrenia classification
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Train a classifier for schizophrenia classification
classifier_schizo = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

# Evaluate the classifier for schizophrenia classification
y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
training_loss_schizo = log_loss(y_train_schizo, classifier_schizo.predict_proba(X_train_tfidf_schizo))
testing_loss_schizo = log_loss(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo))
precision_schizo = precision_score(y_test_schizo, y_pred_schizo)
recall_schizo = recall_score(y_test_schizo, y_pred_schizo)
f1_schizo = f1_score(y_test_schizo, y_pred_schizo)
auc_schizo = roc_auc_score(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo)[:,1])

print("Schizophrenia Classification Metrics:")
print("Accuracy:", accuracy_schizo)
print("Training Loss:", training_loss_schizo)
print("Testing Loss:", testing_loss_schizo)
print("Precision:", precision_schizo)
print("Recall:", recall_schizo)
print("F1 Score:", f1_schizo)
print("AUC:", auc_schizo)

# Classify user input for schizophrenia classification
user_input_schizo = input("Enter the text to classify for schizophrenia: ")
user_input_tfidf_schizo = tfidf_vectorizer_schizo.transform([user_input_schizo])
prediction_schizo = classifier_schizo.predict(user_input_tfidf_schizo)
if prediction_schizo[0] == 1:
    print("The text is classified as schizophrenic.")
else:
    print("The text is classified as non-schizophrenic.")

# Split the dataset into training and testing sets for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X, y_subtype, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for subtype classification
tfidf_vectorizer_subtype = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_subtype = tfidf_vectorizer_subtype.fit_transform(X_train_subtype)
X_test_tfidf_subtype = tfidf_vectorizer_subtype.transform(X_test_subtype)

# Train a classifier for subtype classification
classifier_subtype = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier_subtype.fit(X_train_tfidf_subtype, y_train_subtype)

# Evaluate the classifier for subtype classification
y_pred_subtype = classifier_subtype.predict(X_test_tfidf_subtype)
accuracy_subtype = accuracy_score(y_test_subtype, y_pred_subtype)
training_loss_subtype = log_loss(y_train_subtype, classifier_subtype.predict_proba(X_train_tfidf_subtype))
testing_loss_subtype = log_loss(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype))
precision_subtype = precision_score(y_test_subtype, y_pred_subtype, average='weighted')
recall_subtype = recall_score(y_test_subtype, y_pred_subtype, average='weighted')
f1_subtype = f1_score(y_test_subtype, y_pred_subtype, average='weighted')
auc_subtype = roc_auc_score(y_test_subtype, classifier_subtype.predict_proba(X_test_tfidf_subtype), multi_class='ovr')

print("\nSubtype Classification Metrics:")
print("Accuracy:", accuracy_subtype)
print("Training Loss:", training_loss_subtype)
print("Testing Loss:", testing_loss_subtype)
print("Precision:", precision_subtype)
print("Recall:", recall_subtype)
print("F1 Score:", f1_subtype)
print("AUC:", auc_subtype)

# Classify user input for subtype classification
user_input_subtype = input("Enter the text to classify for subtype: ")
user_input_tfidf_subtype = tfidf_vectorizer_subtype.transform([user_input_subtype])
prediction_subtype = classifier_subtype.predict(user_input_tfidf_subtype)
print("The text is classified as subtype:", prediction_subtype[0])

# Visualization
# Confusion Matrix for Schizophrenia Classification
conf_matrix_schizo = confusion_matrix(y_test_schizo, y_pred_schizo)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_schizo, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.title('Confusion Matrix for Schizophrenia Classification')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

# Confusion Matrix for Subtype Classification
conf_matrix_subtype = confusion_matrix(y_test_subtype, y_pred_subtype)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix_subtype, annot=True, cmap='Greens', fmt='d', cbar=False)
plt.title('Confusion Matrix for Subtype Classification')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()



# Visualization
# Bar Plot for Schizophrenia Classification Metrics
metrics_schizo = {'Accuracy': accuracy_schizo, 'Precision': precision_schizo, 'Recall': recall_schizo, 'F1 Score': f1_schizo, 'AUC': auc_schizo}
plt.figure(figsize=(10, 6))
plt.bar(metrics_schizo.keys(), metrics_schizo.values(), color=['blue', 'green', 'orange', 'red', 'purple'])
plt.title('Schizophrenia Classification Metrics')
plt.xlabel('Metrics')
plt.ylabel('Score')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()

# Pie Chart for Subtype Distribution
subtype_counts = df['subtype'].value_counts()
plt.figure(figsize=(8, 8))
plt.pie(subtype_counts, labels=subtype_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of Subtypes')
plt.show()

# ROC Curve for Schizophrenia Classification
fpr, tpr, _ = roc_curve(y_test_schizo, classifier_schizo.predict_proba(X_test_tfidf_schizo)[:, 1])
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Schizophrenia Classification')
plt.legend(loc='lower right')
plt.show()

# ROC Curve for Subtype Classification (One-vs-Rest strategy)
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(y_train_subtype))):
    fpr[i], tpr[i], _ = roc_curve(y_test_subtype == i, classifier_subtype.predict_proba(X_test_tfidf_subtype)[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(10, 8))
for i in range(len(np.unique(y_train_subtype))):
    plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Subtype Classification')
plt.legend(loc='lower right')
plt.show()

#Mounting Google Drive

from google.colab import drive
drive.mount('/content/drive')

#LSTM For Schizophrenia Prediction

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import LSTM, Embedding, Dense
from keras.utils import to_categorical

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Preprocessing
X = df['clean_text']  # Features
y = df['is_schizophrenic']  # Target

# Convert text labels to categorical labels
label_encoder = LabelEncoder()
y = to_categorical(label_encoder.fit_transform(y))

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tokenization and padding
max_words = 5000
max_len = 100
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train)
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)
X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)

# Define LSTM model
model = Sequential()
model.add(Embedding(max_words, 64, input_length=max_len))
model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(2, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test))

# Evaluate the model
loss, accuracy = model.evaluate(X_test_pad, y_test)
print("Test Accuracy:", accuracy)

# Classify user input
user_input = input("Enter the text to classify: ")
user_input_seq = tokenizer.texts_to_sequences([user_input])
user_input_pad = pad_sequences(user_input_seq, maxlen=max_len)
prediction = model.predict(user_input_pad)
predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])
print("Predicted Label:", predicted_label[0])

#Random Forest For Schizophrenia Prediction

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Preprocessing
X = df['clean_text']  # Features
y = df['is_schizophrenic']  # Target

# Vectorize the text data using TF-IDF
tfidf_vectorizer = TfidfVectorizer(max_features=5000)
X_tfidf = tfidf_vectorizer.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# Train a Random Forest classifier
classifier = RandomForestClassifier(n_estimators=100, random_state=42)
classifier.fit(X_train, y_train)

# Evaluate the classifier
y_pred = classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Classify user input
user_input = input("Enter the text to classify: ")
user_input_tfidf = tfidf_vectorizer.transform([user_input])
prediction = classifier.predict(user_input_tfidf)
if prediction[0] == 1:
    print("The text is classified as schizophrenic.")
else:
    print("The text is classified as non-schizophrenic.")

#LSTM With Minimal Metrics

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import LSTM, Embedding, Dense
from keras.utils import to_categorical

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Preprocessing
X = df['clean_text']  # Features
y = df['is_schizophrenic']  # Target

# Convert text labels to categorical labels
label_encoder = LabelEncoder()
y = to_categorical(label_encoder.fit_transform(y))

# Function to classify subtype based on keywords
def classify_subtype(text):
    # Define keywords for each subtype
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
        # Add more subtypes and their associated keywords as needed
    }

    # Check if any subtype keywords are present in the text
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    # If no subtype keywords are found, return 'unknown'
    return 'unknown'

# Apply subtype classification to each text in the dataset
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Update features and target after adding subtype classification
X = df['clean_text']  # Features
y = df['subtype']  # Target

# Tokenization and padding
max_words = 5000
max_len = 100
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X)
X_seq = tokenizer.texts_to_sequences(X)
X_pad = pad_sequences(X_seq, maxlen=max_len)

# Convert text labels to categorical labels for subtypes
label_encoder_subtype = LabelEncoder()
y_subtype = to_categorical(label_encoder_subtype.fit_transform(y))

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_pad, y_subtype, test_size=0.2, random_state=42)

# Define LSTM model
model = Sequential()
model.add(Embedding(max_words, 64, input_length=max_len))
model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(len(label_encoder_subtype.classes_), activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print("Test Accuracy:", accuracy)

# Classify user input
user_input = input("Enter the text to classify: ")
user_input_seq = tokenizer.texts_to_sequences([user_input])
user_input_pad = pad_sequences(user_input_seq, maxlen=max_len)
prediction = model.predict(user_input_pad)
predicted_label_index = np.argmax(prediction)
predicted_label = label_encoder_subtype.classes_[predicted_label_index]
print("Predicted Subtype:", predicted_label)

#Logistic Regression With Minimal Metrics

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer  # Import TfidfVectorizer
from sklearn.linear_model import LogisticRegression  # Import LogisticRegression
from sklearn.metrics import accuracy_score  # Import accuracy_score

# Function to classify subtype based on keywords
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
        # Add more subtypes and their associated keywords as needed
    }

    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type

    return 'unknown'  # If no subtype keywords are found

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text in the dataset
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Preprocessing
X = df['clean_text']  # Features
y_schizophrenic = df['is_schizophrenic']  # Target for schizophrenia classification
y_subtype = df['subtype']  # Target for subtype classification

# Split the dataset into training and testing sets for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X, y_schizophrenic, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF for schizophrenia classification
tfidf_vectorizer_schizo = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed
X_train_tfidf_schizo = tfidf_vectorizer_schizo.fit_transform(X_train_schizo)
X_test_tfidf_schizo = tfidf_vectorizer_schizo.transform(X_test_schizo)

# Train a classifier for schizophrenia classification
classifier_schizo = LogisticRegression(max_iter=1000)  # You can use any classifier here
classifier_schizo.fit(X_train_tfidf_schizo, y_train_schizo)

# Evaluate the classifier for schizophrenia classification
y_pred_schizo = classifier_schizo.predict(X_test_tfidf_schizo)
accuracy_schizo = accuracy_score(y_test_schizo, y_pred_schizo)
print("Accuracy for schizophrenia classification:", accuracy_schizo)

## Classify user input for schizophrenia classification
user_input_schizo = input("Enter the text to classify for schizophrenia: ")
user_input_tfidf_schizo = tfidf_vectorizer_schizo.transform([user_input_schizo])
prediction_schizo = classifier_schizo.predict(user_input_tfidf_schizo)
if prediction_schizo[0] == 1:
    print("The text is classified as schizophrenic.")
else:
    print("The text is classified as non-schizophrenic.")

#Hybrid BERT Model

#BERT + Random Forest For Schizophrenia Detection and LSTM For Subtype Detection

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score, log_loss
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sentence_transformers import SentenceTransformer

### Part 1: BERT + Random Forest for Schizophrenia Classification ###

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Preprocessing for BERT model
X = df['text']  # Features
y = df['label']  # Target for schizophrenia (binary: schizophrenia or not)

# Load BERT model for sentence embeddings
bert_model = SentenceTransformer('distilbert-base-nli-mean-tokens')

# Generate BERT embeddings for text data
X_bert = bert_model.encode(X, show_progress_bar=True)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_bert, y, test_size=0.2, random_state=42)

# Train a Random Forest classifier on BERT embeddings
classifier = RandomForestClassifier(n_estimators=100, random_state=42)
classifier.fit(X_train, y_train)

# Evaluate the classifier
y_pred = classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("\nBERT + Random Forest - Schizophrenia Classification")
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_report(y_test, y_pred, digits=5))

# Classify user input using the trained Random Forest classifier
user_input = input("Enter the text to classify: ")
user_input_bert = bert_model.encode([user_input])
prediction = classifier.predict(user_input_bert)
if prediction == 'SuicideWatch':
    print("The user is at risk of suicide.")
elif prediction == 'depression':
    print("The user has depression problems.")
else:
    print("Prediction:", prediction)


### Part 2: LSTM Model for Schizophrenia and Subtype Classification ###

# Apply subtype classification to each text in the dataset
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety', 'fear', 'enemy'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'rambling', 'scattered', 'confusion'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'unresponsive'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity'],
        'undifferentiated': ['undifferentiated', 'mixed', 'varied', 'unspecified']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type
    return 'undifferentiated'

df['subtype'] = df['clean_text'].apply(classify_subtype)

# Text preprocessing and tokenization for LSTM
max_words = 5000
max_sequence_length = 100
embedding_dim = 100

# Tokenizer for schizophrenia classification
tokenizer_schizo = Tokenizer(num_words=max_words)
tokenizer_schizo.fit_on_texts(df['clean_text'])
X_sequences_schizo = tokenizer_schizo.texts_to_sequences(df['clean_text'])
X_padded_schizo = pad_sequences(X_sequences_schizo, maxlen=max_sequence_length)

# Encode the target variable for schizophrenia classification
y_schizophrenic = df['is_schizophrenic'].values

# Split the dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X_padded_schizo, y_schizophrenic, test_size=0.2, random_state=42)

# Build LSTM model for schizophrenia classification
model_schizo = Sequential()
model_schizo.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))
model_schizo.add(LSTM(64, return_sequences=True))
model_schizo.add(Dropout(0.5))
model_schizo.add(LSTM(64))
model_schizo.add(Dense(1, activation='sigmoid'))

model_schizo.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model_schizo.fit(X_train_schizo, y_train_schizo, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the LSTM model for schizophrenia classification
y_pred_schizo = model_schizo.predict(X_test_schizo).ravel()
y_pred_schizo_binary = (y_pred_schizo > 0.5).astype(int)
print("\nLSTM - Schizophrenia Classification Metrics:")
print("Accuracy:", accuracy_score(y_test_schizo, y_pred_schizo_binary))
print("Precision:", precision_score(y_test_schizo, y_pred_schizo_binary))
print("Recall:", recall_score(y_test_schizo, y_pred_schizo_binary))
print("F1 Score:", f1_score(y_test_schizo, y_pred_schizo_binary))
print("AUC:", roc_auc_score(y_test_schizo, y_pred_schizo))
print("Log Loss:", log_loss(y_test_schizo, y_pred_schizo))

# Tokenizer for subtype classification
tokenizer_subtype = Tokenizer(num_words=max_words)
tokenizer_subtype.fit_on_texts(df['clean_text'])
X_sequences_subtype = tokenizer_subtype.texts_to_sequences(df['clean_text'])
X_padded_subtype = pad_sequences(X_sequences_subtype, maxlen=max_sequence_length)

# Encode the target variable for subtype classification
y_subtype = df['subtype'].values
label_encoder_subtype = LabelEncoder()
y_subtype_encoded = label_encoder_subtype.fit_transform(y_subtype)
y_subtype_encoded = to_categorical(y_subtype_encoded)  # One-hot encoding

# Split the dataset for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X_padded_subtype, y_subtype_encoded, test_size=0.2, random_state=42)

# Build LSTM model for subtype classification
model_subtype = Sequential()
model_subtype.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))
model_subtype.add(LSTM(64, return_sequences=True))
model_subtype.add(Dropout(0.5))
model_subtype.add(LSTM(64))
model_subtype.add(Dense(len(label_encoder_subtype.classes_), activation='softmax'))

model_subtype.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model_subtype.fit(X_train_subtype, y_train_subtype, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the LSTM model for subtype classification
y_pred_subtype = model_subtype.predict(X_test_subtype)
y_pred_subtype_classes = np.argmax(y_pred_subtype, axis=1)
y_test_subtype_classes = np.argmax(y_test_subtype, axis=1)

print("\nLSTM - Subtype Classification Metrics:")
print("Accuracy:", accuracy_score(y_test_subtype_classes, y_pred_subtype_classes))
print("Precision:", precision_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("Recall:", recall_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("F1 Score:", f1_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))

#BERT + Random Forest Model

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sentence_transformers import SentenceTransformer
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text in the dataset
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type
    return 'undifferentiated'

# Add subtype labels
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Features and Targets
X = df['clean_text']
y_schizophrenia = df['is_schizophrenic']
y_subtype = df['subtype']

# Load BERT model for sentence embeddings
bert_model = SentenceTransformer('distilbert-base-nli-mean-tokens')

# Generate BERT embeddings for text data
X_bert = bert_model.encode(X, show_progress_bar=True)

# Schizophrenia Classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X_bert, y_schizophrenia, test_size=0.2, random_state=42)

# Train a Random Forest classifier for schizophrenia classification
schizo_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
schizo_classifier.fit(X_train_schizo, y_train_schizo)

# Evaluate the schizophrenia classifier
y_pred_schizo = schizo_classifier.predict(X_test_schizo)
print("Schizophrenia Classification Report:")
print("Accuracy:", accuracy_score(y_test_schizo, y_pred_schizo))
print(classification_report(y_test_schizo, y_pred_schizo))

# Subtype Classification
# Encode the subtype labels
label_encoder_subtype = LabelEncoder()
y_subtype_encoded = label_encoder_subtype.fit_transform(y_subtype)

# Convert the labels into one-hot encoded format
y_subtype_encoded = to_categorical(y_subtype_encoded)

# Split data for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X_bert, y_subtype_encoded, test_size=0.2, random_state=42)

# Train a Random Forest classifier for subtype classification
subtype_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
subtype_classifier.fit(X_train_subtype, np.argmax(y_train_subtype, axis=1))

# Evaluate the subtype classifier
y_pred_subtype = subtype_classifier.predict(X_test_subtype)
y_pred_subtype_classes = np.argmax(to_categorical(y_pred_subtype), axis=1)
y_test_subtype_classes = np.argmax(y_test_subtype, axis=1)

print("\nSubtype Classification Report:")
print("Accuracy:", accuracy_score(y_test_subtype_classes, y_pred_subtype_classes))
print("Precision:", precision_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("Recall:", recall_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("F1 Score:", f1_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))

#BERT Model

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from transformers import BertTokenizer, TFBertForSequenceClassification
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset.csv')

# Apply subtype classification to each text in the dataset
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type
    return 'undifferentiated'

# Add subtype labels
df['subtype'] = df['clean_text'].apply(classify_subtype)

# Features and targets
X = df['clean_text']
y_schizophrenia = df['is_schizophrenic']  # Binary labels for schizophrenia classification
y_subtype = df['subtype']  # Multi-class labels for subtype classification

# Tokenizer and model for BERT
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize and encode the input data
def encode_texts(texts, max_len=128):
    return tokenizer(
        list(texts),
        padding=True,
        truncation=True,
        max_length=max_len,
        return_tensors='np'
    )

# Encode the texts
X_encoded = encode_texts(X)

# BERT model for schizophrenia classification (binary classification)
schizo_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)
schizo_model.compile(optimizer=Adam(learning_rate=2e-5), loss='binary_crossentropy', metrics=['accuracy'])

# Train/test split for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X_encoded['input_ids'], y_schizophrenia, test_size=0.2, random_state=42)

# Fine-tune BERT for schizophrenia classification
schizo_model.fit([X_train_schizo], y_train_schizo, epochs=3, batch_size=16, validation_split=0.2)

# Evaluate the schizophrenia model
y_pred_schizo = schizo_model.predict([X_test_schizo])
y_pred_schizo_binary = (y_pred_schizo.logits > 0.5).astype(int).flatten()

print("Schizophrenia Classification Report:")
print("Accuracy:", accuracy_score(y_test_schizo, y_pred_schizo_binary))
print("Precision:", precision_score(y_test_schizo, y_pred_schizo_binary))
print("Recall:", recall_score(y_test_schizo, y_pred_schizo_binary))
print("F1 Score:", f1_score(y_test_schizo, y_pred_schizo_binary))

# BERT model for subtype classification (multi-class classification)
label_encoder_subtype = LabelEncoder()
y_subtype_encoded = label_encoder_subtype.fit_transform(y_subtype)
y_subtype_encoded = to_categorical(y_subtype_encoded)  # One-hot encoding

subtype_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder_subtype.classes_))
subtype_model.compile(optimizer=Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])

# Train/test split for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X_encoded['input_ids'], y_subtype_encoded, test_size=0.2, random_state=42)

# Fine-tune BERT for subtype classification
subtype_model.fit([X_train_subtype], y_train_subtype, epochs=3, batch_size=16, validation_split=0.2)

# Evaluate the subtype model
y_pred_subtype = subtype_model.predict([X_test_subtype])
y_pred_subtype_classes = np.argmax(y_pred_subtype.logits, axis=1)
y_test_subtype_classes = np.argmax(y_test_subtype, axis=1)

print("\nSubtype Classification Report:")
print("Accuracy:", accuracy_score(y_test_subtype_classes, y_pred_subtype_classes))
print("Precision:", precision_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("Recall:", recall_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("F1 Score:", f1_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))

#BERT With Sequential Model

import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sentence_transformers import SentenceTransformer
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

# Assuming you have data X (text data) and y (labels)
# Example dataset for schizophrenia classification
# X = df['clean_text']  # Text data
# y = df['is_schizophrenic']  # Binary labels for schizophrenia

# Preprocessing with Tokenizer
max_length = 128  # Define maximum length of the sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(X)  # Fit tokenizer on the text data
X_sequences = tokenizer.texts_to_sequences(X)  # Convert text to sequences
X_padded = pad_sequences(X_sequences, maxlen=max_length, padding='post')  # Pad sequences

# Split data into train and test sets
X_train_padded, X_test_padded, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)

# Define a function to convert padded sequences back to text
def sequences_to_text(sequences, tokenizer):
    word_index = tokenizer.word_index
    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
    text = []
    for sequence in sequences:
        temp = []
        for idx in sequence:
            word = reverse_word_index.get(idx, '')
            if word:
                temp.append(word)
        text.append(' '.join(temp))
    return text

# Convert padded sequences back to text
X_train_text = sequences_to_text(X_train_padded, tokenizer)  # Convert back to text
X_test_text = sequences_to_text(X_test_padded, tokenizer)  # Convert back to text

# Load pre-trained BERT model for sentence embeddings
bert_model = SentenceTransformer('distilbert-base-nli-mean-tokens')

# Generate BERT embeddings for training and test data
X_train_bert = bert_model.encode(X_train_text, show_progress_bar=True)
X_test_bert = bert_model.encode(X_test_text, show_progress_bar=True)

# Define Sequential model for classification
model = Sequential()
model.add(Dense(256, activation='relu', input_shape=(X_train_bert.shape[1],)))  # Input layer with BERT embedding dimensions
model.add(Dense(128, activation='relu'))  # Hidden layer
model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification (schizophrenic or not)

# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Model summary
model.summary()

# Train the model
model.fit(X_train_bert, y_train, epochs=5, batch_size=64, validation_split=0.1)

# Make predictions
y_pred_prob = model.predict(X_test_bert)
y_pred = (y_pred_prob > 0.5).astype(int).flatten()

# Evaluation
print("BERT Model")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred, digits=5))

#BERT Model For Both Schizophrenia And Subtype Detection

import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sentence_transformers import SentenceTransformer
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

# Load your data (assuming it's already preprocessed)
# X -> your text data (e.g., Reddit posts)
# y_schizo -> your binary labels (schizophrenic vs. not schizophrenic)
# y_subtype -> your subtype labels (paranoid, disorganized, etc.)

# Subtype classification based on keywords
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'spy', 'watched', 'enemy'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'messy'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'unresponsive', 'frozen'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'latent', 'chronic'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'diverse']
    }
    for subtype, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return subtype
    return 'undifferentiated'

# Apply the subtype classifier to the text data
y_subtype = [classify_subtype(text) for text in X]

# Tokenizer to convert text data into sequences (optional step if needed)
max_length = 128  # Define maximum length of the sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(X)
X_sequences = tokenizer.texts_to_sequences(X)
X_padded = pad_sequences(X_sequences, maxlen=max_length, padding='post')

# Split data for both schizophrenia and subtype classification tasks
X_train_padded, X_test_padded, y_train_schizo, y_test_schizo = train_test_split(X_padded, y_schizo, test_size=0.2, random_state=42)
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X_padded, y_subtype, test_size=0.2, random_state=42)

# Function to convert sequences back to text for BERT embedding generation
def sequences_to_text(sequences, tokenizer):
    word_index = tokenizer.word_index
    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
    text = []
    for sequence in sequences:
        temp = []
        for idx in sequence:
            word = reverse_word_index.get(idx, '')
            if word:
                temp.append(word)
        text.append(' '.join(temp))
    return text

# Convert sequences back to text
X_train_text_schizo = sequences_to_text(X_train_padded, tokenizer)
X_test_text_schizo = sequences_to_text(X_test_padded, tokenizer)
X_train_text_subtype = sequences_to_text(X_train_subtype, tokenizer)
X_test_text_subtype = sequences_to_text(X_test_subtype, tokenizer)

# Load BERT model for sentence embeddings
bert_model = SentenceTransformer('distilbert-base-nli-mean-tokens')

# Generate BERT embeddings for schizophrenia classification data
X_train_bert_schizo = bert_model.encode(X_train_text_schizo, show_progress_bar=True)
X_test_bert_schizo = bert_model.encode(X_test_text_schizo, show_progress_bar=True)

# Generate BERT embeddings for subtype classification data
X_train_bert_subtype = bert_model.encode(X_train_text_subtype, show_progress_bar=True)
X_test_bert_subtype = bert_model.encode(X_test_text_subtype, show_progress_bar=True)

# ------------------ Schizophrenia Detection Model ------------------
# Define Sequential model for schizophrenia classification
model_schizo = Sequential()
model_schizo.add(Dense(256, activation='relu', input_shape=(X_train_bert_schizo.shape[1],)))
model_schizo.add(Dense(128, activation='relu'))
model_schizo.add(Dense(1, activation='sigmoid'))  # Binary output for schizophrenic or not

# Compile the model
model_schizo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Model summary
model_schizo.summary()

# Train the model
model_schizo.fit(X_train_bert_schizo, y_train_schizo, epochs=5, batch_size=64, validation_split=0.1)

# Make predictions and evaluate
y_pred_prob_schizo = model_schizo.predict(X_test_bert_schizo)
y_pred_schizo = (y_pred_prob_schizo > 0.5).astype(int).flatten()

# Evaluation metrics for schizophrenia classification
print("Schizophrenia Detection Model")
print("Accuracy:", accuracy_score(y_test_schizo, y_pred_schizo))
print("Classification Report:\n", classification_report(y_test_schizo, y_pred_schizo, digits=5))

# ------------------ Subtype Classification Model ------------------
# Encode subtype labels as integers for multi-class classification
from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical

label_encoder_subtype = LabelEncoder()
y_train_subtype_encoded = label_encoder_subtype.fit_transform(y_train_subtype)
y_test_subtype_encoded = label_encoder_subtype.transform(y_test_subtype)
y_train_subtype_encoded = to_categorical(y_train_subtype_encoded)
y_test_subtype_encoded = to_categorical(y_test_subtype_encoded)

# Define Sequential model for subtype classification
model_subtype = Sequential()
model_subtype.add(Dense(256, activation='relu', input_shape=(X_train_bert_subtype.shape[1],)))
model_subtype.add(Dense(128, activation='relu'))
model_subtype.add(Dense(len(label_encoder_subtype.classes_), activation='softmax'))  # Multi-class classification

# Compile the model
model_subtype.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Model summary
model_subtype.summary()

# Train the model
model_subtype.fit(X_train_bert_subtype, y_train_subtype_encoded, epochs=5, batch_size=64, validation_split=0.1)

# Make predictions and evaluate
y_pred_subtype_prob = model_subtype.predict(X_test_bert_subtype)
y_pred_subtype = np.argmax(y_pred_subtype_prob, axis=1)

# Evaluation metrics for subtype classification
print("\nSubtype Classification Model")
print("Accuracy:", accuracy_score(np.argmax(y_test_subtype_encoded, axis=1), y_pred_subtype))
print("Classification Report:\n", classification_report(np.argmax(y_test_subtype_encoded, axis=1), y_pred_subtype, digits=5))

!pip install python-docx
from docx import Document

# Create a new Document
doc = Document()

# Add a table to the document with 2 columns for Section Title and Page Number
table = doc.add_table(rows=0, cols=2)

# Add headings to the table
heading_cells = table.add_row().cells
heading_cells[0].text = "Section Title"
heading_cells[1].text = "Page Number"

# Data for the table
data = [
    ("ARCHITECTURE OF RANDOM FOREST", "18"),
    ("ARCHITECTURE OF LSTM", "19"),
    ("ARCHITECTURE OF CNN", "19"),
    ("ROC CURVE OF RANDOM FOREST", "25"),
    ("ACCURACY OF LSTM", "26"),
    ("ROC CURVE OF LSTM", "26"),
    ("ACCURACY OF CNN", "26"),
    ("ROC CURVE OF CNN", "27"),
    ("METRICS EVALUATION FOR RANDOM FOREST", "41"),
    ("METRICS VALUES FOR RANDOM FOREST", "41"),
    ("CONFUSION MATRIX FOR RANDOM FOREST", "42"),
    ("METRIC VALUES FOR LSTM", "42"),
    ("CONFUSION MATRIX FOR LSTM", "43"),
    ("METRICS EVALUATION FOR CNN", "44"),
    ("METRICS VALUES FOR CNN", "44"),
    ("CONFUSION MATRIX FOR CNN", "45")
]

# Populate the table with data
for title, page in data:
    cells = table.add_row().cells
    cells[0].text = title
    cells[1].text = page

# Save the document
file_path = "/mnt/data/Aligned_Sections_Table.docx"
doc.save(file_path)

file_path

from google.colab import drive
from docx import Document
from docx.oxml.ns import qn
from docx.oxml import OxmlElement

# Mount Google Drive
drive.mount('/content/drive')

# Create the data list
data = [
    ("Figure No.", "Title", "Page No."),
    ("4.1", "ARCHITECTURE OF RANDOM FOREST", "18"),
    ("4.2", "ARCHITECTURE OF LSTM", "19"),
    ("4.3", "ARCHITECTURE OF CNN", "19"),
    ("5.1", "ROC CURVE OF RANDOM FOREST", "25"),
    ("5.2", "ACCURACY OF LSTM", "26"),
    ("5.3", "ROC CURVE OF LSTM", "26"),
    ("5.4", "ACCURACY OF CNN", "27"),
    ("5.5", "ROC CURVE OF CNN", "27"),
    ("6.1", "METRICS EVALUATION FOR RANDOM FOREST", "41"),
    ("6.2", "METRICS VALUES FOR RANDOM FOREST", "41"),
    ("6.3", "CONFUSION MATRIX FOR RANDOM FOREST", "42"),
    ("6.4", "METRIC VALUES FOR LSTM", "42"),
    ("6.5", "CONFUSION MATRIX FOR LSTM", "43"),
    ("6.6", "METRICS EVALUATION FOR CNN", "44"),
    ("6.7", "METRICS VALUES FOR CNN", "45"),
    ("6.8", "CONFUSION MATRIX FOR CNN", "45")
]

# Create a new Word document
doc = Document()

# Add table with no borders
table = doc.add_table(rows=len(data), cols=3)

# Fill the table with data
for i, row in enumerate(data):
    for j, cell_data in enumerate(row):
        table.cell(i, j).text = cell_data

# Function to remove borders from the table
def remove_borders(table):
    for row in table.rows:
        for cell in row.cells:
            tc_pr = cell._element.get_or_add_tcPr()
            tc_borders = OxmlElement('w:tcBorders')
            for side in ['top', 'left', 'bottom', 'right']:
                border = OxmlElement(f'w:{side}')
                border.set(qn('w:val'), 'nil')
                tc_borders.append(border)
            tc_pr.append(tc_borders)

# Remove borders from the table
remove_borders(table)

# Save the document to Google Drive
file_path = '/content/drive/My Drive/figure_titles_table_no_borders.docx'
doc.save(file_path)

print(f"File saved to {file_path}")

from google.colab import drive
from docx import Document
from docx.oxml.ns import qn
from docx.oxml import OxmlElement

# Mount Google Drive
drive.mount('/content/drive')

# Specify the path to your existing Word document
existing_file_path = '/content/drive/MyDrive/Schizophrenia report final.docx'

# Load the existing document
doc = Document(existing_file_path)

# Create the data list for the new table
data = [
    ("Figure No.", "Title", "Page No."),
    ("4.1", "ARCHITECTURE OF RANDOM FOREST", "18"),
    ("4.2", "ARCHITECTURE OF LSTM", "19"),
    ("4.3", "ARCHITECTURE OF CNN", "19"),
    ("5.1", "ROC CURVE OF RANDOM FOREST", "25"),
    ("5.2", "ACCURACY OF LSTM", "26"),
    ("5.3", "ROC CURVE OF LSTM", "26"),
    ("5.4", "ACCURACY OF CNN", "27"),
    ("5.5", "ROC CURVE OF CNN", "27"),
    ("6.1", "METRICS EVALUATION FOR RANDOM FOREST", "41"),
    ("6.2", "METRICS VALUES FOR RANDOM FOREST", "41"),
    ("6.3", "CONFUSION MATRIX FOR RANDOM FOREST", "42"),
    ("6.4", "METRIC VALUES FOR LSTM", "42"),
    ("6.5", "CONFUSION MATRIX FOR LSTM", "43"),
    ("6.6", "METRICS EVALUATION FOR CNN", "44"),
    ("6.7", "METRICS VALUES FOR CNN", "45"),
    ("6.8", "CONFUSION MATRIX FOR CNN", "45")
]

# Add the new table to the existing document
table = doc.add_table(rows=len(data), cols=3)

# Fill the table with data
for i, row in enumerate(data):
    for j, cell_data in enumerate(row):
        table.cell(i, j).text = cell_data

# Function to remove borders from the table
def remove_borders(table):
    for row in table.rows:
        for cell in row.cells:
            tc_pr = cell._element.get_or_add_tcPr()
            tc_borders = OxmlElement('w:tcBorders')
            for side in ['top', 'left', 'bottom', 'right']:
                border = OxmlElement(f'w:{side}')
                border.set(qn('w:val'), 'nil')
                tc_borders.append(border)
            tc_pr.append(tc_borders)

# Remove borders from the table
remove_borders(table)

# Save the updated document to Google Drive
updated_file_path = '/content/drive/My Drive/updated_document.docx'
doc.save(updated_file_path)

print(f"Updated file saved to {updated_file_path}")

#LSTM For Schizophrenia Dataset 09-1-2024

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/dataset(2).csv')

# Apply subtype classification to each text in the dataset
def classify_subtype(text):
    sub_type_keywords = {
        'paranoid': ['paranoid', 'delusions', 'suspicious', 'persecution', 'conspiracy', 'trust', 'safety',
                     'plot', 'spy', 'stalked', 'watched', 'fear', 'enemy', 'danger', 'threat', 'intruder',
                     'plotting', 'distrust', 'frightening', 'menace', 'enemy', 'untrusting', 'believing',
                     'frightened', 'terror', 'uneasy', 'intimidated', 'fearful', 'apprehensive', 'anxious',
                     'guarded', 'safety', 'scared', 'alarmed', 'paranoia', 'dread', 'nervous', 'threatened',
                     'panicked', 'cowardice', 'worried', 'timid', 'disturbed', 'tense'],
        'disorganized': ['disorganized', 'chaotic', 'incoherent', 'illogical', 'confusion', 'rambling', 'random',
                         'scattered', 'jumbled', 'haphazard', 'disarray', 'unsystematic', 'muddled', 'cluttered',
                         'unorganized', 'chaos', 'messy', 'irrational', 'unstructured', 'unsound', 'chaotic',
                         'disordered', 'messiness', 'disarray', 'haphazard', 'disorganized', 'scatterbrained',
                         'random', 'tangled', 'chaotic', 'confusion', 'mess', 'untidy', 'shambles', 'clutter',
                         'disorder', 'jumble', 'jumbled', 'disorganization', 'disjointed', 'disheveled',
                         'scattered', 'muddle', 'disarranged'],
        'catatonic': ['catatonic', 'immobility', 'rigidity', 'stupor', 'motionless', 'stiff', 'unresponsive',
                      'freezing', 'fixed', 'rigor', 'catatonia', 'blank', 'motionlessness', 'trance', 'inert',
                      'staring', 'rigid', 'lifeless', 'paralysis', 'unmoving', 'motionless', 'frozen', 'still',
                      'paralyzed', 'stationary', 'static', 'stuck', 'rooted', 'unmoving', 'stock-still',
                      'immovable', 'frozen', 'halted', 'pinned', 'at a standstill', 'unbudgeable', 'inanimate',
                      'fixed', 'unmovable', 'lodged', 'stuck', 'standstill', 'unmoving', 'rooted', 'inert',
                      'pinned'],
        'residual': ['residual', 'persistent', 'lingering', 'remaining', 'mild', 'low-intensity', 'enduring',
                     'latent', 'vestigial', 'lingering', 'leftover', 'vestige', 'abiding', 'continuing',
                     'endemic', 'endemic', 'abiding', 'continuous', 'stubborn', 'relapsed', 'persisting',
                     'continuing', 'lingering', 'remaining', 'enduring', 'lasting', 'chronic', 'ongoing',
                     'recurrent', 'long-standing', 'endemic', 'abiding', 'lasting', 'unresolved', 'relentless',
                     'incessant', 'continuous', 'continuous', 'incessant', 'continuing', 'enduring', 'lasting',
                     'persistent', 'chronic', 'endemic', 'incurable', 'abiding'],
        'undifferentiated': ['undifferentiated', 'mixed', 'unspecified', 'varied', 'indeterminate', 'miscellaneous',
                             'assorted', 'unclassifiable', 'unspecified', 'unclear', 'indefinite', 'ambiguous',
                             'diverse', 'assorted', 'multifaceted', 'diversified', 'vague', 'ambiguous',
                             'indistinct', 'inconclusive', 'mixed', 'variable', 'diverse', 'varied', 'divergent',
                             'eclectic', 'broad', 'wide', 'heterogeneous', 'diversified', 'varied', 'broad-based',
                             'extensive', 'all-inclusive', 'comprehensive', 'inclusive', 'incorporating', 'multifarious',
                             'multifaceted', 'diversified', 'mixed', 'miscellaneous', 'sundry', 'assorted', 'various',
                             'sundry', 'miscellaneous', 'assorted', 'various', 'mixed', 'assorted', 'varied']
    }
    for sub_type, keywords in sub_type_keywords.items():
        if any(keyword in text.lower() for keyword in keywords):
            return sub_type
    return 'undifferentiated'

df['subtype'] = df['text'].apply(classify_subtype)

# Text preprocessing and tokenization
max_words = 5000
max_sequence_length = 100
embedding_dim = 100

# Tokenizer for schizophrenia classification
tokenizer_schizo = Tokenizer(num_words=max_words)
tokenizer_schizo.fit_on_texts(df['text'])
X_sequences_schizo = tokenizer_schizo.texts_to_sequences(df['text'])
X_padded_schizo = pad_sequences(X_sequences_schizo, maxlen=max_sequence_length)

# Encode the target variable for schizophrenia classification
y_schizophrenic = df['is_schizophrenic'].values

# Split the dataset for schizophrenia classification
X_train_schizo, X_test_schizo, y_train_schizo, y_test_schizo = train_test_split(X_padded_schizo, y_schizophrenic, test_size=0.2, random_state=42)

# Build LSTM model for schizophrenia classification
model_schizo = Sequential()
model_schizo.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))
model_schizo.add(LSTM(64, return_sequences=True))
model_schizo.add(Dropout(0.5))
model_schizo.add(LSTM(64))
model_schizo.add(Dense(1, activation='sigmoid'))

model_schizo.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model_schizo.fit(X_train_schizo, y_train_schizo, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the model
y_pred_schizo = model_schizo.predict(X_test_schizo).ravel()
y_pred_schizo_binary = (y_pred_schizo > 0.5).astype(int)
print("Schizophrenia Classification Metrics:")
print("Accuracy:", accuracy_score(y_test_schizo, y_pred_schizo_binary))
print("Precision:", precision_score(y_test_schizo, y_pred_schizo_binary))
print("Recall:", recall_score(y_test_schizo, y_pred_schizo_binary))
print("F1 Score:", f1_score(y_test_schizo, y_pred_schizo_binary))
print("AUC:", roc_auc_score(y_test_schizo, y_pred_schizo))
print("Log Loss:", log_loss(y_test_schizo, y_pred_schizo))

# Tokenizer for subtype classification
tokenizer_subtype = Tokenizer(num_words=max_words)
tokenizer_subtype.fit_on_texts(df['text'])
X_sequences_subtype = tokenizer_subtype.texts_to_sequences(df['text'])
X_padded_subtype = pad_sequences(X_sequences_subtype, maxlen=max_sequence_length)

# Encode the target variable for subtype classification
y_subtype = df['subtype'].values
label_encoder_subtype = LabelEncoder()
y_subtype_encoded = label_encoder_subtype.fit_transform(y_subtype)
y_subtype_encoded = to_categorical(y_subtype_encoded)  # One-hot encoding

# Split the dataset for subtype classification
X_train_subtype, X_test_subtype, y_train_subtype, y_test_subtype = train_test_split(X_padded_subtype, y_subtype_encoded, test_size=0.2, random_state=42)

# Build LSTM model for subtype classification
model_subtype = Sequential()
model_subtype.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))
model_subtype.add(LSTM(64, return_sequences=True))
model_subtype.add(Dropout(0.5))
model_subtype.add(LSTM(64))
model_subtype.add(Dense(len(label_encoder_subtype.classes_), activation='softmax'))

model_subtype.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model_subtype.fit(X_train_subtype, y_train_subtype, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the model
y_pred_subtype = model_subtype.predict(X_test_subtype)
y_pred_subtype_classes = np.argmax(y_pred_subtype, axis=1)
y_test_subtype_classes = np.argmax(y_test_subtype, axis=1)

print("\nSubtype Classification Metrics:")
print("Accuracy:", accuracy_score(y_test_subtype_classes, y_pred_subtype_classes))
print("Precision:", precision_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("Recall:", recall_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))
print("F1 Score:", f1_score(y_test_subtype_classes, y_pred_subtype_classes, average='weighted'))

#Schizophrenia Sentiment Analysis

import pandas as pd
import numpy as np
import re
import string
import nltk
from nltk.corpus import stopwords
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from sklearn.model_selection import train_test_split

# Download the NLTK stop words
nltk.download('stopwords')

# Load the dataset
data = pd.read_csv('/content/drive/MyDrive/dataset(2).csv')

# Check the first few rows of the dataset
print(data.head())

# Assume the dataset has columns 'text' and 'label'
# 'label' should be binary (0 or 1) for sentiment analysis

# Text cleaning function
def clean_text(text):
    # Remove special characters, numbers, and emojis
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # Convert to lower case
    text = text.lower()
    # Remove stop words
    stop_words = set(stopwords.words('english'))
    text = ' '.join(word for word in text.split() if word not in stop_words)
    return text

# Apply text cleaning
data['cleaned_text'] = data['text'].apply(clean_text)

# Tokenization and padding
max_words = 10000
max_len = 100

tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(data['cleaned_text'])
sequences = tokenizer.texts_to_sequences(data['cleaned_text'])
X = pad_sequences(sequences, maxlen=max_len)

# Labels
y = data['is_schizophrenic'].values

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the LSTM model
model = Sequential()
model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))
model.add(LSTM(64, return_sequences=True))
model.add(Dropout(0.5))
model.add(LSTM(32))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {accuracy:.2f}')

# Plotting the training history
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

#Hyper Parameter Tuning

!pip install keras-tuner

import pandas as pd
from keras.models import Sequential
from keras.layers import Embedding, LSTM, Dropout, Dense
from keras.preprocessing.sequence import pad_sequences
from keras_tuner import RandomSearch
from sklearn.model_selection import train_test_split

# Load your dataset
custom_df = pd.read_csv('/content/drive/MyDrive/dataset(2).csv')  # Adjust the path as needed
custom_df['cleaned_text'] = custom_df['text'].apply(clean_text)

# Tokenization and padding for custom dataset
sequences_custom = tokenizer.texts_to_sequences(custom_df['cleaned_text'])
X_custom_pad = pad_sequences(sequences_custom, maxlen=max_len)
y_custom = custom_df['is_schizophrenic'].values  # Assuming this column exists

# Define the hypermodel for custom dataset
def build_custom_model(hp):
    model = Sequential()
    model.add(Embedding(input_dim=10000, output_dim=hp.Int('embedding_dim', 64, 256, step=64), input_length=max_len))
    model.add(LSTM(hp.Int('lstm_units', 32, 128, step=32)))
    model.add(Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1)))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Hyperparameter tuning with RandomSearch for custom dataset
tuner_custom = RandomSearch(
    build_custom_model,
    objective='val_accuracy',
    max_trials=5,
    executions_per_trial=1,
    directory='my_dir',
    project_name='custom_dataset_tuning'
)

# Split custom dataset into training and testing sets
X_train_custom, X_test_custom, y_train_custom, y_test_custom = train_test_split(X_custom_pad, y_custom, test_size=0.2, random_state=42)

# Search for the best hyperparameters
tuner_custom.search(X_train_custom, y_train_custom, epochs=5, batch_size=256, validation_split=0.2)

# Retrieve the best model for custom dataset
best_model_custom = tuner_custom.get_best_models(num_models=1)[0]
best_model_custom.summary()

# Evaluate the best model
loss_custom, accuracy_custom = best_model_custom.evaluate(X_test_custom, y_test_custom)
print(f'Test Accuracy (Custom Dataset): {accuracy_custom:.2f}')

#Sentiment Distribution

import seaborn as sns

# Assuming the custom dataset has binary labels (0, 1) for sentiment
sns.countplot(data=custom_df, x='is_schizophrenic')
plt.title('Sentiment Distribution in Custom Dataset')
plt.xlabel('Sentiment (0: Negative, 1: Positive)')
plt.ylabel('Count')
plt.show()